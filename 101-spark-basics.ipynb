{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7dd7243a-b7d3-4e47-b3ec-49cafdebada5",
   "metadata": {},
   "source": [
    "# 101 Spark basics\n",
    "\n",
    "The goal of this lab is to get familiar with Spark programming.\n",
    "\n",
    "- Scala\n",
    "    - [Spark programming guide](https://spark.apache.org/docs/latest/rdd-programming-guide.html)\n",
    "    - [RDD APIs](https://spark.apache.org/docs/latest/api/scala/org/apache/spark/rdd/RDD.html)\n",
    "    - [PairRDD APIs](https://spark.apache.org/docs/latest/api/scala/org/apache/spark/rdd/PairRDDFunctions.html)\n",
    "- Python\n",
    "    - [Spark programming guide](https://spark.apache.org/docs/3.5.0/rdd-programming-guide.html)\n",
    "    - [All RDD APIs](https://spark.apache.org/docs/3.5.0/api/python/reference/api/pyspark.RDD.html)\n",
    "\n",
    "Use `Tab` for autocompletion, `Shift+Tab` for documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11bb4f39692d0432",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T13:12:01.893550Z",
     "start_time": "2024-10-20T13:11:46.380948Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2e281923de95ede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://3fde384286b9:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Local Spark</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local appName=Local Spark>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName(\"Local Spark\") \\\n",
    "    .config('spark.ui.port', '4040') \\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "\n",
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9a0be28e5e823",
   "metadata": {},
   "source": [
    "## 101-1 Spark warm-up\n",
    "\n",
    "Load the ```capra``` and ```divinacommedia``` datasets and try the following actions:\n",
    "- Show their content (```collect```)\n",
    "- Count their rows (```count```)\n",
    "- Split phrases into words (```map``` or ```flatMap```; what’s the difference?)\n",
    "- Check the results (remember: evaluation is lazy)\n",
    "- Try the ```toDebugString``` function to check the execution plan\n",
    "    - In PySpark, use ```toDebugString().decode(\"unicode_escape\")```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cbc4b5cee4a93755",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T13:25:49.644422Z",
     "start_time": "2024-10-20T13:25:49.169096Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['sopra', 'la', 'panca', 'la', 'capra', 'campa'],\n",
       " ['sotto', 'la', 'panca', 'la', 'capra', 'crepa']]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rddCapra = sc.textFile(\"../../../../datasets/capra.txt\")\n",
    "rddDC = sc.textFile(\"../../../../datasets/divinacommedia.txt\")\n",
    "\n",
    "rddCapra.collect()\n",
    "#rddDC.collect()\n",
    "\n",
    "rddCapra.count()\n",
    "#rddDC.count()\n",
    "\n",
    "rddCapra.map(lambda x: x.split(\" \")).collect()     #map suddivide per righe\n",
    "#rddCapra.flatMap(lambda x: x.split(\" \")).collect() #flatMap suddivide per parole\n",
    "\n",
    "#print(rddCapra.toDebugString().decode(\"unicode_escape\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffbc778-306c-4a2b-8da9-1ba38d572d75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "84d04659ace472d8",
   "metadata": {},
   "source": [
    "## 101-2 Basic Spark jobs\n",
    "\n",
    "Implement on Spark the following jobs and test them on both capra and divinacommedia datasets.\n",
    "\n",
    "- **Word count**: count the number of occurrences of each word\n",
    "  - Result: (sopra, 1), (la, 4), …\n",
    "- **Word length count**: count the number of occurrences of words of given lengths\n",
    "  - Result: (2, 4), (5, 8)\n",
    "- Count the average length of words given their first letter (i.e., words that begin with \"s\" have an average length of 5)\n",
    "  - Result: (s, 5), (l, 2), …\n",
    "- Return the inverted index of words (i.e., for each word, list the numbers of lines in which they appear)\n",
    "  - Result: (sopra, (0)), (la, (0, 1)), ...\n",
    "\n",
    "Also, check how sorting works and try to sort key-value RDDs by descending values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5d9fafa5-0702-45b8-9875-9f143a495bbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('campa', 1),\n",
       " ('capra', 2),\n",
       " ('crepa', 1),\n",
       " ('la', 4),\n",
       " ('panca', 2),\n",
       " ('sopra', 1),\n",
       " ('sotto', 1)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rddCapra.flatMap(lambda x: x.split(\" \")).map(lambda x: (x,1)).reduceByKey(lambda x,y: x+y).sortByKey(True).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "eb1ce648-0e4c-4b4a-966f-20908c4ba4b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5, 8), (2, 4)]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rddCapra.flatMap(lambda x: x.split(\" \")).map(lambda x: (len(x),1)).reduceByKey(lambda x,y: x+y).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a8e66e44-b00d-4377-9278-f5041ff44e3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('s', 5.0), ('l', 1.0), ('p', 5.0), ('c', 2.5)]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rddCapra.flatMap(lambda x: x.split(\" \")).map(lambda x: (x[0],(len(x),1))).reduceByKey(lambda acc1, acc2: (acc1[0] + acc2[0], acc1[1] + acc1[1])).mapValues(lambda x: (x[0]/x[1])).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83c49c3689d65e2",
   "metadata": {},
   "source": [
    "## 101-3 Extra Spark jobs\n",
    "\n",
    "Implement the following job.\n",
    "\n",
    "- Co-occurrence count: count the number of co-occurrences in the text. A co-occurrence is defined as \"two distinct words appearing in the same line\".\n",
    "  - In the first line of the *capra* dataset, co-occurrences are:\n",
    "     - (sopra, la), (sopra, panca), (sopra, capra), (sopra, campa)\n",
    "     - (la, sopra), (la, panca), (la, capra), (la, campa) \n",
    "     - (panca, sopra), (panca, la), (panca, capra), (panca, campa)\n",
    "     - (capra, sopra), (capra, la), (capra, panca), (capra, campa)\n",
    "     - (campa, sopra), (campa, la), (campa, panca), (campa, capra)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
